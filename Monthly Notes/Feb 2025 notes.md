
## frontier models

- o3 mini https://news.ycombinator.com/item?id=42890627
- o3 deep research https://news.ycombinator.com/item?id=42913251

## open models

- [mistral small 3](https://news.ycombinator.com/item?id=42877860)

## fundraising

- [OpenAI said to be in talks to raise $40B at a $340B valuation](https://techcrunch.com/2025/01/30/openai-said-to-be-in-talks-to-raise-40b-at-a-340b-valuation/)
	- [Musk-led group makes $97.4 billion bid for control of OpenAI](https://www.voanews.com/a/musk-led-group-makes-97-4-billion-bid-for-control-of-openai/7970292.html "Musk-led group makes $97.4 billion bid for control of OpenAI")
- https://techcrunch.com/2025/02/07/report-ilya-sutskevers-startup-in-talks-to-fundraise-at-roughly-20b-valuation/?guccounter=1

## papers

- [LIMO: less is more for reasoning](https://news.ycombinator.com/item?id=42991676)
- [DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL](https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2)
	- Agentica: [Replicating Deepseek-R1 for $4500: RL Boosts 1.5B Model Beyond o1-preview](https://github.com/agentica-project/deepscaler)


## Demos

- [gemini youtube agent ](https://x.com/DynamicWebPaige/status/1887897486770974770)
- [bytedance omnihuman-1 lipsync model](https://x.com/altryne/status/1886804788513530137) - not released
- [DIY medical research](https://old.reddit.com/r/selfhosted/comments/1ij7s4m/how_i_built_an_open_source_ai_tool_to_find_my/)

## misc

- [microsoft dropping capex](https://www.bloomberg.com/news/articles/2025-02-24/microsoft-cancels-leases-for-ai-data-centers-analyst-says?embedded-checkout=true): https://news.ycombinator.com/item?id=43157831
- continuing deepseek/nvidia [debates](https://x.com/gordic_aleksa/status/1886029511298273561)
- ability to self-verify is what makes self-improvement far superior to distillation from stronger generators - [rich sutton](https://x.com/teortaxesTex/status/1886126526409699632)
- [transformers at meta](https://x.com/techfund1/status/1885732620463477074)
- llama drama <- susan zhang
- [how to train an ai image model on yourself](https://news.ycombinator.com/item?id=42889236)
- sutton on [verificaiton](https://x.com/teortaxesTex/status/1886126526409699632)
- [andrej 2025 llm intro](https://news.ycombinator.com/item?id=42997340)
	- [vibe coding](https://news.ycombinator.com/item?id=42913909)
	- [codenames benchmark](https://x.com/IlyaAbyzov/status/1885784027275424227)
- [roadmap prompt](https://x.com/kregenrek/status/1885979673059876883)
- [hf ultrascale playbook](https://huggingface.co/spaces/nanotron/ultrascale-playbook)
- [how to scale your model by deepmind](https://buttondown.com/ainews/archive/ainews-how-to-scale-your-model-by-deepmind/)
- [revenge of GPT wrappers](https://news.ycombinator.com/item?id=42971442)
- [RLHF book](https://news.ycombinator.com/item?id=42902936)
	- [PPO and GRPO](https://yugeten.github.io/posts/2025/01/ppogrpo/)
	- [GRPO](https://x.com/nrehiew_/status/1885079616248832090): "GRPO gets rid of the Value Model and NOT the Reward Model. This is the main insight since you save memory. The main change between PPO and GRPO is the way the advantage is calculated. PPO uses the Value Model to compute the advantage while GRPO computes the advantage by normalizing against the rollouts in each group."